{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ResNet18 구현에 관한 BasicBlock 클래스 정의\n",
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        # 3x3 필터를 사용 (피처맵 크기를 줄일 때는 stride 값 조절)\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        # 3x3 필터를 사용 (패딩을 1만큼 주기 때문에 너비와 높이가 동일)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential() # identity인 경우. 비어있는 컨테이너이며, forward에서 x를 입력받아 residual 연산을 할 수 있도록 만든다.\n",
    "        if stride != 1: # stride가 1이 아니라면, identity mapping이 아닌 경우이다. 이 경우에는 projection을 수행하여 forward에서 계산될 수 있도록 만든다.\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out)) # 여기까지가 F(x)\n",
    "        out += self.shortcut(x) # F(x) + x\n",
    "        out = F.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_planes = 64\n",
    "\n",
    "        # CIFAR10: 3 x 32 x 32\n",
    "        # 64개의 3x3 필터(filter)를 사용\n",
    "        # (이미지의 첫 시작 채널 개수는 RGB라 3개, 그 다음은 64개의 필터를 만들 것이므로 64개로 out_channel을 설정한다)\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False) # shape=3x32x32 -> shape= 64x32x32\n",
    "        self.bn = nn.BatchNorm2d(64) # BatchNorm의 첫 번째 매개변수는 입력 데이터의 채널 수이다.\n",
    "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1) # shape= 64x32x32 -> shape= 64x32x32\n",
    "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2) # shape= 64x32x32 -> shape= 128x16x16\n",
    "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2) # shape= 128x16x16 -> shape= 256x8x8\n",
    "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2) # shape= 256x8x8 -> shape= 512x4x4\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        \"\"\"\n",
    "        strides = [1]\n",
    "        strides = [2, 1]\n",
    "        strides = [2, 1]\n",
    "        strides = [2, 1]\n",
    "        \"\"\"\n",
    "        strides = [stride] + ([1] * (num_blocks - 1))\n",
    "\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, stride)) # 64, 64\n",
    "            self.in_planes = planes # 다음 레이어를 위해 채널 수 변경\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "    # Outputsize = Inputsize / Poolingsize\n",
    "    # tensor.view()\n",
    "    def forward(self, x):\n",
    "        out = self.bn(self.conv1(x))\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = F.avg_pool2d(out, 4) # input tensor=512x4x4, kernel_size=4 -> 512x1x1\n",
    "        out = out.view(out.size(0), -1) # 512x1x1 -> 512x1\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "# ResNet18 함수 정의\n",
    "def ResNet18():\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 셋 다운 및 로더 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "transfrom_test = transforms.Compose([\n",
    "    transforms.ToTensor()   \n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transfrom_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 훈련 및 테스트 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "net = ResNet18()\n",
    "net = net.to(device)\n",
    "net = torch.nn.DataParallel(net)\n",
    "cudnn.benchmark = True\n",
    "\n",
    "learning_rate = 0.1\n",
    "file_name = 'resnet18_cifar10.pt'\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9, weight_decay=0.0002)\n",
    "\n",
    "def train(epoch):\n",
    "    print('\\n[ Train epoch: %d]' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total_data_num = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        # optimizer.zero_grad()\n",
    "        for param in net.parameters():\n",
    "            param.grad = None\n",
    "\n",
    "        benign_outputs = net(inputs)\n",
    "        loss = criterion(benign_outputs, targets)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted_idx = benign_outputs.max(1)\n",
    "\n",
    "        total_data_num += targets.size(0) # 128\n",
    "        correct += predicted_idx.eq(targets).sum().item() # 예측이 맞은 데이터의 개수를 correct에 더함\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('\\nCurrent batch:', str(batch_idx))\n",
    "            print('Current benign train accuracy:', str(predicted_idx.eq(targets).sum().item() / targets.size(0)))\n",
    "            print('Current benign train loss:', loss.item())\n",
    "    \n",
    "    total_train_accuracy = correct / total_data_num * 100.\n",
    "    print('\\nTotal benign train accuracy:', total_train_accuracy)\n",
    "    print('Total benign train loss:', train_loss)\n",
    "\n",
    "    return total_train_accuracy\n",
    "\n",
    "\n",
    "def test(epoch):\n",
    "    print('\\n[ Test epoch: %d]' % epoch)\n",
    "    net.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    total_data_num = 0\n",
    "\n",
    "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        total_data_num += targets.size(0)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss += criterion(outputs, targets).item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "\n",
    "    total_test_accuracy = correct / total_data_num * 100.\n",
    "    print('\\nTest acuracy:', total_test_accuracy)\n",
    "    print('Test average loss:', loss / total_data_num)\n",
    "\n",
    "    state = {\n",
    "        'net': net.state_dict()\n",
    "    }\n",
    "    if not os.path.isdir('checkpoint'):\n",
    "        os.mkdir('checkpoint')\n",
    "    torch.save(state, './checkpoint/' + file_name)\n",
    "    print('Model Saved!')\n",
    "\n",
    "    return total_test_accuracy\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch): # Learning rate scheduler\n",
    "    lr = learning_rate\n",
    "    if epoch >= 100:\n",
    "        lr /= 10\n",
    "    if epoch >= 150:\n",
    "        lr /= 10\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[ Train epoch: 0]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.1015625\n",
      "Current benign train loss: 2.334784984588623\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.3125\n",
      "Current benign train loss: 1.9909483194351196\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.3359375\n",
      "Current benign train loss: 1.79517662525177\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.34375\n",
      "Current benign train loss: 1.6984061002731323\n",
      "\n",
      "Total benign train accuracy: 30.284\n",
      "Total benign train loss: 769.2804585695267\n",
      "\n",
      "[ Test epoch: 0]\n",
      "\n",
      "Test acuracy: 36.36\n",
      "Test average loss: 0.01884780024290085\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 1]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.3828125\n",
      "Current benign train loss: 1.5822407007217407\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.4296875\n",
      "Current benign train loss: 1.5059665441513062\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.4609375\n",
      "Current benign train loss: 1.4823895692825317\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.40625\n",
      "Current benign train loss: 1.510015606880188\n",
      "\n",
      "Total benign train accuracy: 46.696\n",
      "Total benign train loss: 568.0980999469757\n",
      "\n",
      "[ Test epoch: 1]\n",
      "\n",
      "Test acuracy: 48.17\n",
      "Test average loss: 0.014499224662780762\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 2]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.5078125\n",
      "Current benign train loss: 1.2908339500427246\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.5859375\n",
      "Current benign train loss: 1.211663007736206\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.6484375\n",
      "Current benign train loss: 1.0718456506729126\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.0967189073562622\n",
      "\n",
      "Total benign train accuracy: 57.668\n",
      "Total benign train loss: 459.43678945302963\n",
      "\n",
      "[ Test epoch: 2]\n",
      "\n",
      "Test acuracy: 54.269999999999996\n",
      "Test average loss: 0.012742447352409363\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 3]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.59375\n",
      "Current benign train loss: 1.1369515657424927\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.6953125\n",
      "Current benign train loss: 0.9321380257606506\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.578125\n",
      "Current benign train loss: 1.2125835418701172\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7109375\n",
      "Current benign train loss: 0.9658832550048828\n",
      "\n",
      "Total benign train accuracy: 65.634\n",
      "Total benign train loss: 378.337649166584\n",
      "\n",
      "[ Test epoch: 3]\n",
      "\n",
      "Test acuracy: 60.77\n",
      "Test average loss: 0.011805454498529435\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 4]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7265625\n",
      "Current benign train loss: 0.885817289352417\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.703125\n",
      "Current benign train loss: 0.8793550729751587\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.6626450419425964\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.7578125\n",
      "Current benign train loss: 0.6274509429931641\n",
      "\n",
      "Total benign train accuracy: 72.02\n",
      "Total benign train loss: 312.72384214401245\n",
      "\n",
      "[ Test epoch: 4]\n",
      "\n",
      "Test acuracy: 68.19\n",
      "Test average loss: 0.00935948781967163\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 5]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.78125\n",
      "Current benign train loss: 0.6635148525238037\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.71875\n",
      "Current benign train loss: 0.8629714250564575\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.765625\n",
      "Current benign train loss: 0.7132285833358765\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.6422005295753479\n",
      "\n",
      "Total benign train accuracy: 76.298\n",
      "Total benign train loss: 264.41912883520126\n",
      "\n",
      "[ Test epoch: 5]\n",
      "\n",
      "Test acuracy: 73.2\n",
      "Test average loss: 0.0076975297510623935\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 6]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.7770590782165527\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.528793454170227\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5909417271614075\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8046875\n",
      "Current benign train loss: 0.5428088903427124\n",
      "\n",
      "Total benign train accuracy: 79.33\n",
      "Total benign train loss: 233.79598793387413\n",
      "\n",
      "[ Test epoch: 6]\n",
      "\n",
      "Test acuracy: 76.46\n",
      "Test average loss: 0.007023251330852509\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 7]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.4038473963737488\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5203350186347961\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.7890625\n",
      "Current benign train loss: 0.568087637424469\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.46980151534080505\n",
      "\n",
      "Total benign train accuracy: 81.516\n",
      "Total benign train loss: 210.42712479829788\n",
      "\n",
      "[ Test epoch: 7]\n",
      "\n",
      "Test acuracy: 75.26\n",
      "Test average loss: 0.007409547036886215\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 8]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.7421875\n",
      "Current benign train loss: 0.6280298829078674\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4082670211791992\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.4208030104637146\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.796875\n",
      "Current benign train loss: 0.5651558637619019\n",
      "\n",
      "Total benign train accuracy: 82.806\n",
      "Total benign train loss: 192.82639527320862\n",
      "\n",
      "[ Test epoch: 8]\n",
      "\n",
      "Test acuracy: 80.08\n",
      "Test average loss: 0.005980407392978668\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 9]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8125\n",
      "Current benign train loss: 0.5887575149536133\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4852379858493805\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3788892924785614\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4512147307395935\n",
      "\n",
      "Total benign train accuracy: 84.088\n",
      "Total benign train loss: 179.09348049759865\n",
      "\n",
      "[ Test epoch: 9]\n",
      "\n",
      "Test acuracy: 82.61\n",
      "Test average loss: 0.005062313637137413\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 10]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.38344287872314453\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.44905194640159607\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.5074344277381897\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8203125\n",
      "Current benign train loss: 0.48105698823928833\n",
      "\n",
      "Total benign train accuracy: 85.326\n",
      "Total benign train loss: 165.9656290858984\n",
      "\n",
      "[ Test epoch: 10]\n",
      "\n",
      "Test acuracy: 83.0\n",
      "Test average loss: 0.005033665525913239\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 11]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.2910469174385071\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2822301387786865\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.30821532011032104\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.5081517696380615\n",
      "\n",
      "Total benign train accuracy: 86.036\n",
      "Total benign train loss: 157.31814831495285\n",
      "\n",
      "[ Test epoch: 11]\n",
      "\n",
      "Test acuracy: 83.0\n",
      "Test average loss: 0.005115269133448601\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 12]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8515625\n",
      "Current benign train loss: 0.4618054926395416\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.27627894282341003\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.41786059737205505\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3025323450565338\n",
      "\n",
      "Total benign train accuracy: 86.896\n",
      "Total benign train loss: 147.19167132675648\n",
      "\n",
      "[ Test epoch: 12]\n",
      "\n",
      "Test acuracy: 84.75\n",
      "Test average loss: 0.004612134277820587\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 13]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.37632182240486145\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3671691417694092\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.859375\n",
      "Current benign train loss: 0.3454696536064148\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.29728826880455017\n",
      "\n",
      "Total benign train accuracy: 87.672\n",
      "Total benign train loss: 140.54302985966206\n",
      "\n",
      "[ Test epoch: 13]\n",
      "\n",
      "Test acuracy: 82.77\n",
      "Test average loss: 0.005254852353036404\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 14]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.27890968322753906\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2812366187572479\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.5009505152702332\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.3016830384731293\n",
      "\n",
      "Total benign train accuracy: 88.458\n",
      "Total benign train loss: 132.5025031864643\n",
      "\n",
      "[ Test epoch: 14]\n",
      "\n",
      "Test acuracy: 77.75999999999999\n",
      "Test average loss: 0.006848883074522019\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 15]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.84375\n",
      "Current benign train loss: 0.4416565001010895\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.33663231134414673\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8359375\n",
      "Current benign train loss: 0.44308027625083923\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.828125\n",
      "Current benign train loss: 0.4189213216304779\n",
      "\n",
      "Total benign train accuracy: 88.44\n",
      "Total benign train loss: 130.34646686911583\n",
      "\n",
      "[ Test epoch: 15]\n",
      "\n",
      "Test acuracy: 84.07\n",
      "Test average loss: 0.004752309355139732\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 16]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.39394745230674744\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.31539398431777954\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.22622932493686676\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.32243847846984863\n",
      "\n",
      "Total benign train accuracy: 89.022\n",
      "Total benign train loss: 124.62817342579365\n",
      "\n",
      "[ Test epoch: 16]\n",
      "\n",
      "Test acuracy: 85.16\n",
      "Test average loss: 0.004428172476589679\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 17]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.2769072949886322\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2819061577320099\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.23146525025367737\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.3545086979866028\n",
      "\n",
      "Total benign train accuracy: 89.436\n",
      "Total benign train loss: 120.14959046244621\n",
      "\n",
      "[ Test epoch: 17]\n",
      "\n",
      "Test acuracy: 85.92\n",
      "Test average loss: 0.00421953555047512\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 18]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.32072725892066956\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.3279097080230713\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.32892027497291565\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.34899935126304626\n",
      "\n",
      "Total benign train accuracy: 89.64\n",
      "Total benign train loss: 117.32072857767344\n",
      "\n",
      "[ Test epoch: 18]\n",
      "\n",
      "Test acuracy: 84.93\n",
      "Test average loss: 0.004411567258834839\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 19]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.3221921920776367\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2843937873840332\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2729269862174988\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3230440020561218\n",
      "\n",
      "Total benign train accuracy: 90.058\n",
      "Total benign train loss: 111.9933099001646\n",
      "\n",
      "[ Test epoch: 19]\n",
      "\n",
      "Test acuracy: 84.7\n",
      "Test average loss: 0.004684591543674469\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 20]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.29700255393981934\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2779535949230194\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.17169417440891266\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.14568030834197998\n",
      "\n",
      "Total benign train accuracy: 90.15\n",
      "Total benign train loss: 110.22179281711578\n",
      "\n",
      "[ Test epoch: 20]\n",
      "\n",
      "Test acuracy: 85.28999999999999\n",
      "Test average loss: 0.004541916973888874\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 21]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.18767207860946655\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.33391883969306946\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.27073341608047485\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.23209154605865479\n",
      "\n",
      "Total benign train accuracy: 90.808\n",
      "Total benign train loss: 105.22427554428577\n",
      "\n",
      "[ Test epoch: 21]\n",
      "\n",
      "Test acuracy: 85.22\n",
      "Test average loss: 0.00462162299156189\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 22]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.18933069705963135\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2135380506515503\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.23648880422115326\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.24559293687343597\n",
      "\n",
      "Total benign train accuracy: 90.658\n",
      "Total benign train loss: 104.73636567592621\n",
      "\n",
      "[ Test epoch: 22]\n",
      "\n",
      "Test acuracy: 87.25\n",
      "Test average loss: 0.003916245812177658\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 23]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.18140268325805664\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.2722136676311493\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.22944802045822144\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.28566640615463257\n",
      "\n",
      "Total benign train accuracy: 91.004\n",
      "Total benign train loss: 102.01228615641594\n",
      "\n",
      "[ Test epoch: 23]\n",
      "\n",
      "Test acuracy: 86.92999999999999\n",
      "Test average loss: 0.004029920575022697\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 24]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.240117609500885\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2959129214286804\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.16635115444660187\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.2343900501728058\n",
      "\n",
      "Total benign train accuracy: 91.21\n",
      "Total benign train loss: 99.25769075006247\n",
      "\n",
      "[ Test epoch: 24]\n",
      "\n",
      "Test acuracy: 86.71\n",
      "Test average loss: 0.004035699687898159\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 25]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19052065908908844\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2586507201194763\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.21219174563884735\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.27184635400772095\n",
      "\n",
      "Total benign train accuracy: 91.336\n",
      "Total benign train loss: 98.56019899249077\n",
      "\n",
      "[ Test epoch: 25]\n",
      "\n",
      "Test acuracy: 85.98\n",
      "Test average loss: 0.004555630342662334\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 26]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2759402096271515\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.2501850724220276\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.25142809748649597\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.33787620067596436\n",
      "\n",
      "Total benign train accuracy: 91.322\n",
      "Total benign train loss: 96.95681201666594\n",
      "\n",
      "[ Test epoch: 26]\n",
      "\n",
      "Test acuracy: 87.17\n",
      "Test average loss: 0.00378355899900198\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 27]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.2530005872249603\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.20933310687541962\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.333332896232605\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2216741442680359\n",
      "\n",
      "Total benign train accuracy: 91.77\n",
      "Total benign train loss: 93.4002510458231\n",
      "\n",
      "[ Test epoch: 27]\n",
      "\n",
      "Test acuracy: 86.37\n",
      "Test average loss: 0.004249259315431118\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 28]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2348184883594513\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.12961918115615845\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2088257372379303\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15657134354114532\n",
      "\n",
      "Total benign train accuracy: 91.672\n",
      "Total benign train loss: 93.51638612151146\n",
      "\n",
      "[ Test epoch: 28]\n",
      "\n",
      "Test acuracy: 83.86\n",
      "Test average loss: 0.005123751509189606\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 29]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1630007028579712\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1638994961977005\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1895453929901123\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8671875\n",
      "Current benign train loss: 0.360670804977417\n",
      "\n",
      "Total benign train accuracy: 91.946\n",
      "Total benign train loss: 90.11203204840422\n",
      "\n",
      "[ Test epoch: 29]\n",
      "\n",
      "Test acuracy: 87.31\n",
      "Test average loss: 0.0040017239227890964\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 30]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1487809717655182\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.25357016921043396\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.3149760663509369\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.26436999440193176\n",
      "\n",
      "Total benign train accuracy: 92.11\n",
      "Total benign train loss: 88.55180084705353\n",
      "\n",
      "[ Test epoch: 30]\n",
      "\n",
      "Test acuracy: 87.22999999999999\n",
      "Test average loss: 0.004092742379009724\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 31]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.17249400913715363\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1514275074005127\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.19100333750247955\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.23602506518363953\n",
      "\n",
      "Total benign train accuracy: 91.958\n",
      "Total benign train loss: 91.67339921742678\n",
      "\n",
      "[ Test epoch: 31]\n",
      "\n",
      "Test acuracy: 87.09\n",
      "Test average loss: 0.00400842600017786\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 32]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.20457959175109863\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2307877540588379\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.19323520362377167\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1761617362499237\n",
      "\n",
      "Total benign train accuracy: 92.424\n",
      "Total benign train loss: 85.00164030492306\n",
      "\n",
      "[ Test epoch: 32]\n",
      "\n",
      "Test acuracy: 85.47\n",
      "Test average loss: 0.0044068471595644955\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 33]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.17451858520507812\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1779361516237259\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12359204143285751\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.20030486583709717\n",
      "\n",
      "Total benign train accuracy: 92.446\n",
      "Total benign train loss: 84.52246417850256\n",
      "\n",
      "[ Test epoch: 33]\n",
      "\n",
      "Test acuracy: 87.08\n",
      "Test average loss: 0.003942030066251755\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 34]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.2161668837070465\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1737387478351593\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.34221065044403076\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.3914419710636139\n",
      "\n",
      "Total benign train accuracy: 92.526\n",
      "Total benign train loss: 85.3982837125659\n",
      "\n",
      "[ Test epoch: 34]\n",
      "\n",
      "Test acuracy: 87.56\n",
      "Test average loss: 0.0038882585912942886\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 35]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2739357650279999\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.28498056530952454\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.1783064752817154\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2151474952697754\n",
      "\n",
      "Total benign train accuracy: 92.558\n",
      "Total benign train loss: 84.89314163476229\n",
      "\n",
      "[ Test epoch: 35]\n",
      "\n",
      "Test acuracy: 88.08\n",
      "Test average loss: 0.00375891802161932\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 36]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1362842172384262\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.18625670671463013\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12858237326145172\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1897026151418686\n",
      "\n",
      "Total benign train accuracy: 92.938\n",
      "Total benign train loss: 80.76536132395267\n",
      "\n",
      "[ Test epoch: 36]\n",
      "\n",
      "Test acuracy: 87.51\n",
      "Test average loss: 0.0038904063388705253\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 37]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.17189832031726837\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1543668657541275\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1606205701828003\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1413879692554474\n",
      "\n",
      "Total benign train accuracy: 92.746\n",
      "Total benign train loss: 82.13589233160019\n",
      "\n",
      "[ Test epoch: 37]\n",
      "\n",
      "Test acuracy: 87.33999999999999\n",
      "Test average loss: 0.0042630170553922654\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 38]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.23649314045906067\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.18131320178508759\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1788996011018753\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20733542740345\n",
      "\n",
      "Total benign train accuracy: 92.798\n",
      "Total benign train loss: 81.42768029123545\n",
      "\n",
      "[ Test epoch: 38]\n",
      "\n",
      "Test acuracy: 88.94999999999999\n",
      "Test average loss: 0.0034944200187921525\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 39]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.28035974502563477\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2231941819190979\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.2092566043138504\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.2196209579706192\n",
      "\n",
      "Total benign train accuracy: 92.872\n",
      "Total benign train loss: 79.8117712251842\n",
      "\n",
      "[ Test epoch: 39]\n",
      "\n",
      "Test acuracy: 88.97\n",
      "Test average loss: 0.0036387294501066206\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 40]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1354072242975235\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.263611376285553\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1908695548772812\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.162075936794281\n",
      "\n",
      "Total benign train accuracy: 93.012\n",
      "Total benign train loss: 79.60651208460331\n",
      "\n",
      "[ Test epoch: 40]\n",
      "\n",
      "Test acuracy: 88.27000000000001\n",
      "Test average loss: 0.003718169501423836\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 41]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2295389026403427\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2288932055234909\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.15510141849517822\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1930818408727646\n",
      "\n",
      "Total benign train accuracy: 92.996\n",
      "Total benign train loss: 80.11913648992777\n",
      "\n",
      "[ Test epoch: 41]\n",
      "\n",
      "Test acuracy: 86.14\n",
      "Test average loss: 0.00433304885327816\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 42]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.24201495945453644\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2295815497636795\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.12940137088298798\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14304305613040924\n",
      "\n",
      "Total benign train accuracy: 93.074\n",
      "Total benign train loss: 77.80665583908558\n",
      "\n",
      "[ Test epoch: 42]\n",
      "\n",
      "Test acuracy: 87.21\n",
      "Test average loss: 0.004393534757196903\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 43]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.21437013149261475\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.30559518933296204\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.16707958281040192\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13216818869113922\n",
      "\n",
      "Total benign train accuracy: 93.296\n",
      "Total benign train loss: 76.38728805631399\n",
      "\n",
      "[ Test epoch: 43]\n",
      "\n",
      "Test acuracy: 87.67\n",
      "Test average loss: 0.003919138762354851\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 44]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2645135819911957\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15132305026054382\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1625126600265503\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.15341348946094513\n",
      "\n",
      "Total benign train accuracy: 93.0\n",
      "Total benign train loss: 78.30415900051594\n",
      "\n",
      "[ Test epoch: 44]\n",
      "\n",
      "Test acuracy: 88.12\n",
      "Test average loss: 0.003925119300186634\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 45]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.18320924043655396\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1192234605550766\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.18055768311023712\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.19683879613876343\n",
      "\n",
      "Total benign train accuracy: 93.278\n",
      "Total benign train loss: 76.022749889642\n",
      "\n",
      "[ Test epoch: 45]\n",
      "\n",
      "Test acuracy: 84.99\n",
      "Test average loss: 0.005261542235314846\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 46]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.20636709034442902\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19693782925605774\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.21908362209796906\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1553429514169693\n",
      "\n",
      "Total benign train accuracy: 93.324\n",
      "Total benign train loss: 75.26630099117756\n",
      "\n",
      "[ Test epoch: 46]\n",
      "\n",
      "Test acuracy: 89.29\n",
      "Test average loss: 0.0035437940657138825\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 47]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20177163183689117\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.21791104972362518\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11732514947652817\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.21348713338375092\n",
      "\n",
      "Total benign train accuracy: 93.314\n",
      "Total benign train loss: 74.63873905688524\n",
      "\n",
      "[ Test epoch: 47]\n",
      "\n",
      "Test acuracy: 90.16\n",
      "Test average loss: 0.0032793734960258007\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 48]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.22846730053424835\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.11238209158182144\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.24326135218143463\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.22121597826480865\n",
      "\n",
      "Total benign train accuracy: 93.224\n",
      "Total benign train loss: 76.87645664066076\n",
      "\n",
      "[ Test epoch: 48]\n",
      "\n",
      "Test acuracy: 87.97\n",
      "Test average loss: 0.0038686652019619943\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 49]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.18272723257541656\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.19088993966579437\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.23461666703224182\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.16761931777000427\n",
      "\n",
      "Total benign train accuracy: 93.694\n",
      "Total benign train loss: 72.28680088371038\n",
      "\n",
      "[ Test epoch: 49]\n",
      "\n",
      "Test acuracy: 88.41\n",
      "Test average loss: 0.003836642944812775\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 50]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2766578197479248\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.20685140788555145\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.16517238318920135\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1149284839630127\n",
      "\n",
      "Total benign train accuracy: 93.584\n",
      "Total benign train loss: 73.1470323652029\n",
      "\n",
      "[ Test epoch: 50]\n",
      "\n",
      "Test acuracy: 87.5\n",
      "Test average loss: 0.004137542523443699\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 51]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.25395727157592773\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1678471863269806\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20473149418830872\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.20364932715892792\n",
      "\n",
      "Total benign train accuracy: 93.54\n",
      "Total benign train loss: 73.13074162602425\n",
      "\n",
      "[ Test epoch: 51]\n",
      "\n",
      "Test acuracy: 83.52000000000001\n",
      "Test average loss: 0.0060034918457269664\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 52]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1704346090555191\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.21792902052402496\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19975633919239044\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.17966622114181519\n",
      "\n",
      "Total benign train accuracy: 93.414\n",
      "Total benign train loss: 74.1308184787631\n",
      "\n",
      "[ Test epoch: 52]\n",
      "\n",
      "Test acuracy: 89.27000000000001\n",
      "Test average loss: 0.0034215872570872306\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 53]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08144067972898483\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19076794385910034\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1823425590991974\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14438574016094208\n",
      "\n",
      "Total benign train accuracy: 93.614\n",
      "Total benign train loss: 70.84198822453618\n",
      "\n",
      "[ Test epoch: 53]\n",
      "\n",
      "Test acuracy: 87.91\n",
      "Test average loss: 0.003903529532253742\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 54]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.23557168245315552\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1560959815979004\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.19169488549232483\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.19183655083179474\n",
      "\n",
      "Total benign train accuracy: 93.686\n",
      "Total benign train loss: 71.06549736857414\n",
      "\n",
      "[ Test epoch: 54]\n",
      "\n",
      "Test acuracy: 83.91\n",
      "Test average loss: 0.005424574752151966\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 55]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.17474372684955597\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12289229780435562\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1306319385766983\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11559206992387772\n",
      "\n",
      "Total benign train accuracy: 93.398\n",
      "Total benign train loss: 72.68091052770615\n",
      "\n",
      "[ Test epoch: 55]\n",
      "\n",
      "Test acuracy: 87.33999999999999\n",
      "Test average loss: 0.004085388302803039\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 56]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15695618093013763\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10463153570890427\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09317170828580856\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.23326638340950012\n",
      "\n",
      "Total benign train accuracy: 93.594\n",
      "Total benign train loss: 72.6597373560071\n",
      "\n",
      "[ Test epoch: 56]\n",
      "\n",
      "Test acuracy: 84.26\n",
      "Test average loss: 0.005198897424340248\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 57]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08241962641477585\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11635717004537582\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1591821163892746\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09534429758787155\n",
      "\n",
      "Total benign train accuracy: 93.784\n",
      "Total benign train loss: 69.43970173597336\n",
      "\n",
      "[ Test epoch: 57]\n",
      "\n",
      "Test acuracy: 88.77000000000001\n",
      "Test average loss: 0.003623619240522385\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 58]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.12416297197341919\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13124319911003113\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09133324027061462\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1583511233329773\n",
      "\n",
      "Total benign train accuracy: 93.612\n",
      "Total benign train loss: 71.53696493804455\n",
      "\n",
      "[ Test epoch: 58]\n",
      "\n",
      "Test acuracy: 88.23\n",
      "Test average loss: 0.0037234492406249048\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 59]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1703803390264511\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.06647831946611404\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16540096700191498\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.23631523549556732\n",
      "\n",
      "Total benign train accuracy: 93.802\n",
      "Total benign train loss: 69.97769884392619\n",
      "\n",
      "[ Test epoch: 59]\n",
      "\n",
      "Test acuracy: 88.39\n",
      "Test average loss: 0.0040026904225349425\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 60]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.2535002529621124\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.16573069989681244\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16186948120594025\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1264876127243042\n",
      "\n",
      "Total benign train accuracy: 93.89\n",
      "Total benign train loss: 69.56174419820309\n",
      "\n",
      "[ Test epoch: 60]\n",
      "\n",
      "Test acuracy: 89.47\n",
      "Test average loss: 0.003451397515833378\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 61]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.16875076293945312\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1661093384027481\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.18601086735725403\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.20455895364284515\n",
      "\n",
      "Total benign train accuracy: 93.832\n",
      "Total benign train loss: 70.17593494802713\n",
      "\n",
      "[ Test epoch: 61]\n",
      "\n",
      "Test acuracy: 88.47\n",
      "Test average loss: 0.003710109741985798\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 62]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07023784518241882\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2218087762594223\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16142131388187408\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.25268593430519104\n",
      "\n",
      "Total benign train accuracy: 93.94\n",
      "Total benign train loss: 68.54654060676694\n",
      "\n",
      "[ Test epoch: 62]\n",
      "\n",
      "Test acuracy: 87.18\n",
      "Test average loss: 0.0044358887210488316\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 63]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09454764425754547\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.167873814702034\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2347925901412964\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2325107902288437\n",
      "\n",
      "Total benign train accuracy: 94.106\n",
      "Total benign train loss: 67.76933245360851\n",
      "\n",
      "[ Test epoch: 63]\n",
      "\n",
      "Test acuracy: 89.03999999999999\n",
      "Test average loss: 0.00356761317551136\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 64]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10717644542455673\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.16197673976421356\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.17931850254535675\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13911424577236176\n",
      "\n",
      "Total benign train accuracy: 93.86\n",
      "Total benign train loss: 68.8312374651432\n",
      "\n",
      "[ Test epoch: 64]\n",
      "\n",
      "Test acuracy: 89.2\n",
      "Test average loss: 0.0035453003384172915\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 65]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2444094717502594\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.17777317762374878\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.20675727725028992\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.23213037848472595\n",
      "\n",
      "Total benign train accuracy: 94.044\n",
      "Total benign train loss: 67.43678799644113\n",
      "\n",
      "[ Test epoch: 65]\n",
      "\n",
      "Test acuracy: 87.27000000000001\n",
      "Test average loss: 0.004362064518034458\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 66]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10084597766399384\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1693352311849594\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.19745947420597076\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.29689523577690125\n",
      "\n",
      "Total benign train accuracy: 93.784\n",
      "Total benign train loss: 70.91951809823513\n",
      "\n",
      "[ Test epoch: 66]\n",
      "\n",
      "Test acuracy: 86.65\n",
      "Test average loss: 0.004474840953946114\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 67]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.20750316977500916\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08861343562602997\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.3041098415851593\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.17816445231437683\n",
      "\n",
      "Total benign train accuracy: 93.922\n",
      "Total benign train loss: 68.10727180540562\n",
      "\n",
      "[ Test epoch: 67]\n",
      "\n",
      "Test acuracy: 87.58\n",
      "Test average loss: 0.00398238575309515\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 68]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.2035345882177353\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.2882029414176941\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15993428230285645\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.19060850143432617\n",
      "\n",
      "Total benign train accuracy: 94.024\n",
      "Total benign train loss: 67.96834173426032\n",
      "\n",
      "[ Test epoch: 68]\n",
      "\n",
      "Test acuracy: 87.53999999999999\n",
      "Test average loss: 0.004204801566898822\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 69]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.135279580950737\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.11769523471593857\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.2389213889837265\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.10789524763822556\n",
      "\n",
      "Total benign train accuracy: 94.086\n",
      "Total benign train loss: 67.32863609492779\n",
      "\n",
      "[ Test epoch: 69]\n",
      "\n",
      "Test acuracy: 85.5\n",
      "Test average loss: 0.004993160825967789\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 70]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.15173591673374176\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11549318581819534\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.07214418053627014\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1815194934606552\n",
      "\n",
      "Total benign train accuracy: 94.048\n",
      "Total benign train loss: 67.4085340462625\n",
      "\n",
      "[ Test epoch: 70]\n",
      "\n",
      "Test acuracy: 89.27000000000001\n",
      "Test average loss: 0.0034102810159325598\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 71]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09629566967487335\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15127071738243103\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.14909259974956512\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.20240476727485657\n",
      "\n",
      "Total benign train accuracy: 93.884\n",
      "Total benign train loss: 68.06307363882661\n",
      "\n",
      "[ Test epoch: 71]\n",
      "\n",
      "Test acuracy: 89.44\n",
      "Test average loss: 0.0032428243830800057\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 72]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1630360335111618\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1696215569972992\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.20312157273292542\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2142636477947235\n",
      "\n",
      "Total benign train accuracy: 94.134\n",
      "Total benign train loss: 66.98777722939849\n",
      "\n",
      "[ Test epoch: 72]\n",
      "\n",
      "Test acuracy: 89.64\n",
      "Test average loss: 0.003187108513712883\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 73]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13519801199436188\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15447251498699188\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14121602475643158\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.21051165461540222\n",
      "\n",
      "Total benign train accuracy: 94.294\n",
      "Total benign train loss: 65.06739344075322\n",
      "\n",
      "[ Test epoch: 73]\n",
      "\n",
      "Test acuracy: 87.74\n",
      "Test average loss: 0.004155161513388157\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 74]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.10794003307819366\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.1694304496049881\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08400017768144608\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.206515833735466\n",
      "\n",
      "Total benign train accuracy: 94.068\n",
      "Total benign train loss: 67.31368594616652\n",
      "\n",
      "[ Test epoch: 74]\n",
      "\n",
      "Test acuracy: 87.86\n",
      "Test average loss: 0.003998924182355404\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 75]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1417977213859558\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.08268620818853378\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.22485806047916412\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.2523339092731476\n",
      "\n",
      "Total benign train accuracy: 94.036\n",
      "Total benign train loss: 67.60583426058292\n",
      "\n",
      "[ Test epoch: 75]\n",
      "\n",
      "Test acuracy: 87.98\n",
      "Test average loss: 0.003948097161948681\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 76]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.17319141328334808\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.14243347942829132\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.23289331793785095\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09324061125516891\n",
      "\n",
      "Total benign train accuracy: 94.196\n",
      "Total benign train loss: 65.91232175379992\n",
      "\n",
      "[ Test epoch: 76]\n",
      "\n",
      "Test acuracy: 86.07000000000001\n",
      "Test average loss: 0.0044169908151030545\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 77]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.8984375\n",
      "Current benign train loss: 0.24407590925693512\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10265914350748062\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08231915533542633\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.09969071298837662\n",
      "\n",
      "Total benign train accuracy: 94.108\n",
      "Total benign train loss: 66.24474819749594\n",
      "\n",
      "[ Test epoch: 77]\n",
      "\n",
      "Test acuracy: 87.74\n",
      "Test average loss: 0.00426308686286211\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 78]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16658012568950653\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12696149945259094\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.23775427043437958\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.17306572198867798\n",
      "\n",
      "Total benign train accuracy: 94.012\n",
      "Total benign train loss: 67.13190878927708\n",
      "\n",
      "[ Test epoch: 78]\n",
      "\n",
      "Test acuracy: 88.67\n",
      "Test average loss: 0.003596436934173107\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 79]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.09167126566171646\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.21065843105316162\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11261788010597229\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.2225274294614792\n",
      "\n",
      "Total benign train accuracy: 94.402\n",
      "Total benign train loss: 63.68667433038354\n",
      "\n",
      "[ Test epoch: 79]\n",
      "\n",
      "Test acuracy: 89.92999999999999\n",
      "Test average loss: 0.0032929694294929505\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 80]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2274799644947052\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.08073078095912933\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.1701800674200058\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.20488466322422028\n",
      "\n",
      "Total benign train accuracy: 94.234\n",
      "Total benign train loss: 64.55351949110627\n",
      "\n",
      "[ Test epoch: 80]\n",
      "\n",
      "Test acuracy: 88.81\n",
      "Test average loss: 0.0036720085069537165\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 81]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1939219981431961\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.1993848979473114\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.17707514762878418\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.1635541319847107\n",
      "\n",
      "Total benign train accuracy: 94.272\n",
      "Total benign train loss: 65.95419724285603\n",
      "\n",
      "[ Test epoch: 81]\n",
      "\n",
      "Test acuracy: 89.28\n",
      "Test average loss: 0.0033557810306549074\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 82]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.19711512327194214\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.20235426723957062\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.19915276765823364\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.15457148849964142\n",
      "\n",
      "Total benign train accuracy: 94.054\n",
      "Total benign train loss: 66.09527192264795\n",
      "\n",
      "[ Test epoch: 82]\n",
      "\n",
      "Test acuracy: 88.8\n",
      "Test average loss: 0.003790071885287762\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 83]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1370200514793396\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.05998926982283592\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.875\n",
      "Current benign train loss: 0.23937714099884033\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.2197297215461731\n",
      "\n",
      "Total benign train accuracy: 94.224\n",
      "Total benign train loss: 66.26929512992501\n",
      "\n",
      "[ Test epoch: 83]\n",
      "\n",
      "Test acuracy: 90.27\n",
      "Test average loss: 0.0031902860715985297\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 84]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12268923223018646\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12502756714820862\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.2138853520154953\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.12507078051567078\n",
      "\n",
      "Total benign train accuracy: 94.318\n",
      "Total benign train loss: 65.66466960310936\n",
      "\n",
      "[ Test epoch: 84]\n",
      "\n",
      "Test acuracy: 88.42\n",
      "Test average loss: 0.003695069944858551\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 85]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13214969635009766\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.19148649275302887\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.890625\n",
      "Current benign train loss: 0.293034166097641\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.23216457664966583\n",
      "\n",
      "Total benign train accuracy: 94.392\n",
      "Total benign train loss: 64.24180402606726\n",
      "\n",
      "[ Test epoch: 85]\n",
      "\n",
      "Test acuracy: 89.27000000000001\n",
      "Test average loss: 0.0035330868974328042\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 86]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1210833266377449\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.19725780189037323\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.20398446917533875\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.16291627287864685\n",
      "\n",
      "Total benign train accuracy: 94.386\n",
      "Total benign train loss: 64.47994704917073\n",
      "\n",
      "[ Test epoch: 86]\n",
      "\n",
      "Test acuracy: 88.1\n",
      "Test average loss: 0.0040128687307238575\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 87]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12292828410863876\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14910925924777985\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1568906158208847\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.14133542776107788\n",
      "\n",
      "Total benign train accuracy: 94.276\n",
      "Total benign train loss: 65.10210418328643\n",
      "\n",
      "[ Test epoch: 87]\n",
      "\n",
      "Test acuracy: 86.7\n",
      "Test average loss: 0.00453597844094038\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 88]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.11911007761955261\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1295389086008072\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9140625\n",
      "Current benign train loss: 0.2027072012424469\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.19640356302261353\n",
      "\n",
      "Total benign train accuracy: 94.404\n",
      "Total benign train loss: 63.880528040230274\n",
      "\n",
      "[ Test epoch: 88]\n",
      "\n",
      "Test acuracy: 88.98\n",
      "Test average loss: 0.0035531273350119593\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 89]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13959179818630219\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15867234766483307\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.20601297914981842\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.18762467801570892\n",
      "\n",
      "Total benign train accuracy: 94.342\n",
      "Total benign train loss: 63.33433913812041\n",
      "\n",
      "[ Test epoch: 89]\n",
      "\n",
      "Test acuracy: 88.92999999999999\n",
      "Test average loss: 0.003515737534314394\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 90]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9296875\n",
      "Current benign train loss: 0.13341698050498962\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13549794256687164\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.23141701519489288\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.12857933342456818\n",
      "\n",
      "Total benign train accuracy: 94.176\n",
      "Total benign train loss: 65.28191421926022\n",
      "\n",
      "[ Test epoch: 90]\n",
      "\n",
      "Test acuracy: 88.03999999999999\n",
      "Test average loss: 0.003973434457182884\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 91]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.12244873493909836\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.053551167249679565\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.18808022141456604\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.14888976514339447\n",
      "\n",
      "Total benign train accuracy: 94.222\n",
      "Total benign train loss: 65.37206010520458\n",
      "\n",
      "[ Test epoch: 91]\n",
      "\n",
      "Test acuracy: 87.64\n",
      "Test average loss: 0.004004268133640289\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 92]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.16449421644210815\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.0939541608095169\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.13996019959449768\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15780597925186157\n",
      "\n",
      "Total benign train accuracy: 94.476\n",
      "Total benign train loss: 62.83173282071948\n",
      "\n",
      "[ Test epoch: 92]\n",
      "\n",
      "Test acuracy: 89.68\n",
      "Test average loss: 0.003322447086498141\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 93]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05832219868898392\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.10691167414188385\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.12455186992883682\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05866159498691559\n",
      "\n",
      "Total benign train accuracy: 94.518\n",
      "Total benign train loss: 62.928654074668884\n",
      "\n",
      "[ Test epoch: 93]\n",
      "\n",
      "Test acuracy: 86.83\n",
      "Test average loss: 0.004600312684476375\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 94]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.13097645342350006\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.18891146779060364\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.15875856578350067\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.20863795280456543\n",
      "\n",
      "Total benign train accuracy: 94.214\n",
      "Total benign train loss: 66.41621480509639\n",
      "\n",
      "[ Test epoch: 94]\n",
      "\n",
      "Test acuracy: 87.61\n",
      "Test average loss: 0.004042774605751038\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 95]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11572547256946564\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.0994565486907959\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.13915258646011353\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.1050356775522232\n",
      "\n",
      "Total benign train accuracy: 94.672\n",
      "Total benign train loss: 61.45048337057233\n",
      "\n",
      "[ Test epoch: 95]\n",
      "\n",
      "Test acuracy: 90.36999999999999\n",
      "Test average loss: 0.003106603701412678\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 96]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08650999516248703\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.1739342212677002\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.1714775562286377\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.1402846872806549\n",
      "\n",
      "Total benign train accuracy: 94.418\n",
      "Total benign train loss: 62.99564399942756\n",
      "\n",
      "[ Test epoch: 96]\n",
      "\n",
      "Test acuracy: 89.0\n",
      "Test average loss: 0.003547647048532963\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 97]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.14525526762008667\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.8828125\n",
      "Current benign train loss: 0.3043741285800934\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.23209646344184875\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.19921627640724182\n",
      "\n",
      "Total benign train accuracy: 94.242\n",
      "Total benign train loss: 64.66051371395588\n",
      "\n",
      "[ Test epoch: 97]\n",
      "\n",
      "Test acuracy: 90.44\n",
      "Test average loss: 0.0031160403817892075\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 98]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.11659052968025208\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.08317866921424866\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.14102117717266083\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9375\n",
      "Current benign train loss: 0.15609019994735718\n",
      "\n",
      "Total benign train accuracy: 94.416\n",
      "Total benign train loss: 63.56768638268113\n",
      "\n",
      "[ Test epoch: 98]\n",
      "\n",
      "Test acuracy: 88.51\n",
      "Test average loss: 0.003724236150085926\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 99]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9453125\n",
      "Current benign train loss: 0.1487952321767807\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.10111600905656815\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.90625\n",
      "Current benign train loss: 0.1861388385295868\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.921875\n",
      "Current benign train loss: 0.209284245967865\n",
      "\n",
      "Total benign train accuracy: 94.494\n",
      "Total benign train loss: 62.50931350886822\n",
      "\n",
      "[ Test epoch: 99]\n",
      "\n",
      "Test acuracy: 89.71000000000001\n",
      "Test average loss: 0.003439256975054741\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 100]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.953125\n",
      "Current benign train loss: 0.17447565495967865\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.06627606600522995\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.040481701493263245\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9609375\n",
      "Current benign train loss: 0.06992058455944061\n",
      "\n",
      "Total benign train accuracy: 97.57\n",
      "Total benign train loss: 29.743700441904366\n",
      "\n",
      "[ Test epoch: 100]\n",
      "\n",
      "Test acuracy: 93.95\n",
      "Test average loss: 0.0019516194947063923\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 101]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.022321023046970367\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030977655202150345\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.05365118756890297\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.031238308176398277\n",
      "\n",
      "Total benign train accuracy: 98.674\n",
      "Total benign train loss: 16.932781773153692\n",
      "\n",
      "[ Test epoch: 101]\n",
      "\n",
      "Test acuracy: 94.11\n",
      "Test average loss: 0.0019113333381712437\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 102]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03860245272517204\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03087150864303112\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.05144999548792839\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.037815239280462265\n",
      "\n",
      "Total benign train accuracy: 99.06\n",
      "Total benign train loss: 12.619889330118895\n",
      "\n",
      "[ Test epoch: 102]\n",
      "\n",
      "Test acuracy: 94.43\n",
      "Test average loss: 0.0019043893050402403\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 103]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.03231002762913704\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.96875\n",
      "Current benign train loss: 0.050848960876464844\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.017465315759181976\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.03167824447154999\n",
      "\n",
      "Total benign train accuracy: 99.18\n",
      "Total benign train loss: 10.530824549030513\n",
      "\n",
      "[ Test epoch: 103]\n",
      "\n",
      "Test acuracy: 94.52000000000001\n",
      "Test average loss: 0.0018966847952455283\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 104]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.024792972952127457\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00836760550737381\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.013495899736881256\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.01007448323071003\n",
      "\n",
      "Total benign train accuracy: 99.336\n",
      "Total benign train loss: 8.918201733846217\n",
      "\n",
      "[ Test epoch: 104]\n",
      "\n",
      "Test acuracy: 94.5\n",
      "Test average loss: 0.0019408650524914265\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 105]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.984375\n",
      "Current benign train loss: 0.019582875072956085\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006944212131202221\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02134385146200657\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9765625\n",
      "Current benign train loss: 0.04905061051249504\n",
      "\n",
      "Total benign train accuracy: 99.458\n",
      "Total benign train loss: 7.356134944828227\n",
      "\n",
      "[ Test epoch: 105]\n",
      "\n",
      "Test acuracy: 94.51\n",
      "Test average loss: 0.0019506673879921437\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 106]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.02073095180094242\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004347602836787701\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.045737385749816895\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0148459542542696\n",
      "\n",
      "Total benign train accuracy: 99.536\n",
      "Total benign train loss: 6.662077546934597\n",
      "\n",
      "[ Test epoch: 106]\n",
      "\n",
      "Test acuracy: 94.75\n",
      "Test average loss: 0.0019235108602792025\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 107]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012283316813409328\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0060148765332996845\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003147979499772191\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007178479339927435\n",
      "\n",
      "Total benign train accuracy: 99.578\n",
      "Total benign train loss: 5.654716057470068\n",
      "\n",
      "[ Test epoch: 107]\n",
      "\n",
      "Test acuracy: 94.67\n",
      "Test average loss: 0.0019560507211834194\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 108]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008342461660504341\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00706625496968627\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0037230029702186584\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0375269390642643\n",
      "\n",
      "Total benign train accuracy: 99.572\n",
      "Total benign train loss: 5.481019543367438\n",
      "\n",
      "[ Test epoch: 108]\n",
      "\n",
      "Test acuracy: 94.74000000000001\n",
      "Test average loss: 0.0019707825556397438\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 109]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.011110222898423672\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.014939667657017708\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.01060021948069334\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0038553792983293533\n",
      "\n",
      "Total benign train accuracy: 99.674\n",
      "Total benign train loss: 4.763993921573274\n",
      "\n",
      "[ Test epoch: 109]\n",
      "\n",
      "Test acuracy: 94.77\n",
      "Test average loss: 0.0019650402817875147\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 110]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003789272392168641\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009704501368105412\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010484596714377403\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003783217864111066\n",
      "\n",
      "Total benign train accuracy: 99.718\n",
      "Total benign train loss: 4.401271408831235\n",
      "\n",
      "[ Test epoch: 110]\n",
      "\n",
      "Test acuracy: 94.81\n",
      "Test average loss: 0.001978147908300161\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 111]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010727878659963608\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005123237147927284\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002174536231905222\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004618323408067226\n",
      "\n",
      "Total benign train accuracy: 99.782\n",
      "Total benign train loss: 3.6783876778790727\n",
      "\n",
      "[ Test epoch: 111]\n",
      "\n",
      "Test acuracy: 94.84\n",
      "Test average loss: 0.001954158278182149\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 112]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005401815287768841\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001370560028590262\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.012285172939300537\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002260184148326516\n",
      "\n",
      "Total benign train accuracy: 99.77\n",
      "Total benign train loss: 3.6601093176868744\n",
      "\n",
      "[ Test epoch: 112]\n",
      "\n",
      "Test acuracy: 94.71000000000001\n",
      "Test average loss: 0.0020030788611620663\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 113]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005617572460323572\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005048984661698341\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002299973275512457\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0054849120788276196\n",
      "\n",
      "Total benign train accuracy: 99.798\n",
      "Total benign train loss: 3.366141359321773\n",
      "\n",
      "[ Test epoch: 113]\n",
      "\n",
      "Test acuracy: 94.93\n",
      "Test average loss: 0.001971700796112418\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 114]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001753812888637185\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002777061192318797\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.01627447083592415\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.028524288907647133\n",
      "\n",
      "Total benign train accuracy: 99.842\n",
      "Total benign train loss: 2.8347508671868127\n",
      "\n",
      "[ Test epoch: 114]\n",
      "\n",
      "Test acuracy: 94.82000000000001\n",
      "Test average loss: 0.0020302183900028467\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 115]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0036115385591983795\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0031183843966573477\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006618360057473183\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.010901478119194508\n",
      "\n",
      "Total benign train accuracy: 99.824\n",
      "Total benign train loss: 2.825606829195749\n",
      "\n",
      "[ Test epoch: 115]\n",
      "\n",
      "Test acuracy: 94.78\n",
      "Test average loss: 0.002015593498572707\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 116]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.030735822394490242\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016251028282567859\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.016469918191432953\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003091869642958045\n",
      "\n",
      "Total benign train accuracy: 99.846\n",
      "Total benign train loss: 2.6595827287528664\n",
      "\n",
      "[ Test epoch: 116]\n",
      "\n",
      "Test acuracy: 94.8\n",
      "Test average loss: 0.0020333414675667884\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 117]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020036606583744287\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009389925980940461\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002657906152307987\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004691982641816139\n",
      "\n",
      "Total benign train accuracy: 99.86\n",
      "Total benign train loss: 2.3777476841351017\n",
      "\n",
      "[ Test epoch: 117]\n",
      "\n",
      "Test acuracy: 94.78\n",
      "Test average loss: 0.0020473782079294322\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 118]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021542052272707224\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011815198231488466\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021986772771924734\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0061870901845395565\n",
      "\n",
      "Total benign train accuracy: 99.886\n",
      "Total benign train loss: 2.162168034061324\n",
      "\n",
      "[ Test epoch: 118]\n",
      "\n",
      "Test acuracy: 94.98\n",
      "Test average loss: 0.0020631105192005636\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 119]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.011829692870378494\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0030535694677382708\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006330045405775309\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004011562094092369\n",
      "\n",
      "Total benign train accuracy: 99.884\n",
      "Total benign train loss: 2.046035692153964\n",
      "\n",
      "[ Test epoch: 119]\n",
      "\n",
      "Test acuracy: 94.94\n",
      "Test average loss: 0.002063051690533757\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 120]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0034249965101480484\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.011212969198822975\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005851981230080128\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003515208140015602\n",
      "\n",
      "Total benign train accuracy: 99.882\n",
      "Total benign train loss: 2.106385825725738\n",
      "\n",
      "[ Test epoch: 120]\n",
      "\n",
      "Test acuracy: 94.89\n",
      "Test average loss: 0.0020814610047265886\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 121]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007041681557893753\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009180033230222762\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018105655908584595\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0073392512276768684\n",
      "\n",
      "Total benign train accuracy: 99.892\n",
      "Total benign train loss: 2.0176970916072605\n",
      "\n",
      "[ Test epoch: 121]\n",
      "\n",
      "Test acuracy: 94.81\n",
      "Test average loss: 0.0020943452201783656\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 122]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011523523135110736\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.008330374956130981\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.010085648857057095\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0167727991938591\n",
      "\n",
      "Total benign train accuracy: 99.884\n",
      "Total benign train loss: 1.9974611039215233\n",
      "\n",
      "[ Test epoch: 122]\n",
      "\n",
      "Test acuracy: 94.86\n",
      "Test average loss: 0.0020856293780729175\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 123]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010729244910180569\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001170893432572484\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013795376289635897\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002029660390689969\n",
      "\n",
      "Total benign train accuracy: 99.904\n",
      "Total benign train loss: 1.881828181387391\n",
      "\n",
      "[ Test epoch: 123]\n",
      "\n",
      "Test acuracy: 94.88\n",
      "Test average loss: 0.002046442695148289\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 124]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003956269472837448\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.0077951145358383656\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005902017466723919\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009936037240549922\n",
      "\n",
      "Total benign train accuracy: 99.904\n",
      "Total benign train loss: 1.6976362535788212\n",
      "\n",
      "[ Test epoch: 124]\n",
      "\n",
      "Test acuracy: 95.02000000000001\n",
      "Test average loss: 0.0020675808005034923\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 125]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002391441725194454\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.009030384011566639\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007034286856651306\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0023593022488057613\n",
      "\n",
      "Total benign train accuracy: 99.924\n",
      "Total benign train loss: 1.6420302264450584\n",
      "\n",
      "[ Test epoch: 125]\n",
      "\n",
      "Test acuracy: 94.84\n",
      "Test average loss: 0.0020955569721758365\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 126]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006110058166086674\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016305180033668876\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006032310193404555\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007988455472514033\n",
      "\n",
      "Total benign train accuracy: 99.922\n",
      "Total benign train loss: 1.5655007346067578\n",
      "\n",
      "[ Test epoch: 126]\n",
      "\n",
      "Test acuracy: 95.05\n",
      "Test average loss: 0.002070238370075822\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 127]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011701799230650067\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.007713129743933678\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018174309516325593\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003155822865664959\n",
      "\n",
      "Total benign train accuracy: 99.924\n",
      "Total benign train loss: 1.5827777131053153\n",
      "\n",
      "[ Test epoch: 127]\n",
      "\n",
      "Test acuracy: 94.94\n",
      "Test average loss: 0.0020965173192322253\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 128]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013350832741707563\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0026259496808052063\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003187419380992651\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012222755467519164\n",
      "\n",
      "Total benign train accuracy: 99.914\n",
      "Total benign train loss: 1.6142136259295512\n",
      "\n",
      "[ Test epoch: 128]\n",
      "\n",
      "Test acuracy: 95.06\n",
      "Test average loss: 0.002041366169601679\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 129]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.008215994574129581\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004466134123504162\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0025118356570601463\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004209805279970169\n",
      "\n",
      "Total benign train accuracy: 99.942\n",
      "Total benign train loss: 1.3178633004717994\n",
      "\n",
      "[ Test epoch: 129]\n",
      "\n",
      "Test acuracy: 94.89\n",
      "Test average loss: 0.002107048069499433\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 130]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.008352024480700493\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003019521478563547\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001235213945619762\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006151463836431503\n",
      "\n",
      "Total benign train accuracy: 99.942\n",
      "Total benign train loss: 1.4196480672690086\n",
      "\n",
      "[ Test epoch: 130]\n",
      "\n",
      "Test acuracy: 94.88\n",
      "Test average loss: 0.0021027008727192878\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 131]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011931834742426872\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007580049568787217\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018758800579234958\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000804692623205483\n",
      "\n",
      "Total benign train accuracy: 99.93\n",
      "Total benign train loss: 1.3420270172937308\n",
      "\n",
      "[ Test epoch: 131]\n",
      "\n",
      "Test acuracy: 95.06\n",
      "Test average loss: 0.002068628138117492\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 132]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017196113476529717\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0030952678062021732\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003490122966468334\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007869151886552572\n",
      "\n",
      "Total benign train accuracy: 99.958\n",
      "Total benign train loss: 1.2096624211408198\n",
      "\n",
      "[ Test epoch: 132]\n",
      "\n",
      "Test acuracy: 95.04\n",
      "Test average loss: 0.002071771339327097\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 133]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005363934324122965\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000657854019664228\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.010960845276713371\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003826138796284795\n",
      "\n",
      "Total benign train accuracy: 99.96\n",
      "Total benign train loss: 1.2106036651530303\n",
      "\n",
      "[ Test epoch: 133]\n",
      "\n",
      "Test acuracy: 94.96\n",
      "Test average loss: 0.002072956660576165\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 134]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012507039355114102\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008317799074575305\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002465959871187806\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0024462316650897264\n",
      "\n",
      "Total benign train accuracy: 99.968\n",
      "Total benign train loss: 1.1242431981372647\n",
      "\n",
      "[ Test epoch: 134]\n",
      "\n",
      "Test acuracy: 94.77\n",
      "Test average loss: 0.0021008284101262688\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 135]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0031410425435751677\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003803551197052002\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004448692314326763\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.013565726578235626\n",
      "\n",
      "Total benign train accuracy: 99.958\n",
      "Total benign train loss: 1.0734489147434942\n",
      "\n",
      "[ Test epoch: 135]\n",
      "\n",
      "Test acuracy: 95.0\n",
      "Test average loss: 0.0020570059528574347\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 136]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009034349932335317\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001924503711052239\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022384505718946457\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002150929532945156\n",
      "\n",
      "Total benign train accuracy: 99.968\n",
      "Total benign train loss: 1.007929910585517\n",
      "\n",
      "[ Test epoch: 136]\n",
      "\n",
      "Test acuracy: 94.82000000000001\n",
      "Test average loss: 0.002093265450373292\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 137]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011959864059463143\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001973246457055211\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013579482911154628\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001871562679298222\n",
      "\n",
      "Total benign train accuracy: 99.974\n",
      "Total benign train loss: 1.0064489724754822\n",
      "\n",
      "[ Test epoch: 137]\n",
      "\n",
      "Test acuracy: 95.0\n",
      "Test average loss: 0.002074449747428298\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 138]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.006412569433450699\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004766018129885197\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003717129584401846\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006646917900070548\n",
      "\n",
      "Total benign train accuracy: 99.964\n",
      "Total benign train loss: 1.0215055070293602\n",
      "\n",
      "[ Test epoch: 138]\n",
      "\n",
      "Test acuracy: 95.02000000000001\n",
      "Test average loss: 0.0020523697663098572\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 139]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003088852157816291\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013642425183206797\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0032508803997188807\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.011824453249573708\n",
      "\n",
      "Total benign train accuracy: 99.944\n",
      "Total benign train loss: 1.1715231050329749\n",
      "\n",
      "[ Test epoch: 139]\n",
      "\n",
      "Test acuracy: 94.87\n",
      "Test average loss: 0.0020530660837888718\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 140]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006925123161636293\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001206487650051713\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0065205879509449005\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016324241878464818\n",
      "\n",
      "Total benign train accuracy: 99.958\n",
      "Total benign train loss: 1.1022488803137094\n",
      "\n",
      "[ Test epoch: 140]\n",
      "\n",
      "Test acuracy: 95.11\n",
      "Test average loss: 0.0020404779817909\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 141]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004714622162282467\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009962549665942788\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005286385305225849\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010844130301848054\n",
      "\n",
      "Total benign train accuracy: 99.952\n",
      "Total benign train loss: 1.062611054017907\n",
      "\n",
      "[ Test epoch: 141]\n",
      "\n",
      "Test acuracy: 95.11\n",
      "Test average loss: 0.0020374686628580095\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 142]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001959824236109853\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019250140758231282\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002398923970758915\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008451146422885358\n",
      "\n",
      "Total benign train accuracy: 99.944\n",
      "Total benign train loss: 1.1279486142739188\n",
      "\n",
      "[ Test epoch: 142]\n",
      "\n",
      "Test acuracy: 94.98\n",
      "Test average loss: 0.002038200918212533\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 143]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003986097406595945\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005614035180769861\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0033654996659606695\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0039928681217134\n",
      "\n",
      "Total benign train accuracy: 99.974\n",
      "Total benign train loss: 1.0148274525417946\n",
      "\n",
      "[ Test epoch: 143]\n",
      "\n",
      "Test acuracy: 95.14\n",
      "Test average loss: 0.002022841080650687\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 144]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001052745385095477\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005030616885051131\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002103036968037486\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0029809395782649517\n",
      "\n",
      "Total benign train accuracy: 99.966\n",
      "Total benign train loss: 0.946148927876493\n",
      "\n",
      "[ Test epoch: 144]\n",
      "\n",
      "Test acuracy: 95.1\n",
      "Test average loss: 0.0020202835753560066\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 145]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009087422513402998\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012837722897529602\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0022296616807579994\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007294681272469461\n",
      "\n",
      "Total benign train accuracy: 99.97\n",
      "Total benign train loss: 0.9943595814111177\n",
      "\n",
      "[ Test epoch: 145]\n",
      "\n",
      "Test acuracy: 95.13000000000001\n",
      "Test average loss: 0.0020413161646574735\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 146]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015154603170230985\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.012056475505232811\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010273527586832643\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008011058089323342\n",
      "\n",
      "Total benign train accuracy: 99.936\n",
      "Total benign train loss: 1.191332622867776\n",
      "\n",
      "[ Test epoch: 146]\n",
      "\n",
      "Test acuracy: 94.94\n",
      "Test average loss: 0.002072169231250882\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 147]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014182947343215346\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009564788779243827\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.005259707570075989\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000765363743994385\n",
      "\n",
      "Total benign train accuracy: 99.952\n",
      "Total benign train loss: 1.0906634638668038\n",
      "\n",
      "[ Test epoch: 147]\n",
      "\n",
      "Test acuracy: 95.08\n",
      "Test average loss: 0.0020472599010914563\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 148]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012284397380426526\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017704385099932551\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001696005230769515\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002569823060184717\n",
      "\n",
      "Total benign train accuracy: 99.96\n",
      "Total benign train loss: 1.004030868964037\n",
      "\n",
      "[ Test epoch: 148]\n",
      "\n",
      "Test acuracy: 94.87\n",
      "Test average loss: 0.002187366520240903\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 149]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002618104452267289\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010474685113877058\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007218461250886321\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009702618699520826\n",
      "\n",
      "Total benign train accuracy: 99.964\n",
      "Total benign train loss: 1.0280972773907706\n",
      "\n",
      "[ Test epoch: 149]\n",
      "\n",
      "Test acuracy: 95.00999999999999\n",
      "Test average loss: 0.0020764488987624645\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 150]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007857291493564844\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011967950267717242\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016820466844365\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015120648313313723\n",
      "\n",
      "Total benign train accuracy: 99.954\n",
      "Total benign train loss: 0.9417696816090029\n",
      "\n",
      "[ Test epoch: 150]\n",
      "\n",
      "Test acuracy: 95.11\n",
      "Test average loss: 0.002040430775284767\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 151]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002346605760976672\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010949302231892943\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019827261567115784\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014897886430844665\n",
      "\n",
      "Total benign train accuracy: 99.97\n",
      "Total benign train loss: 0.8213247146923095\n",
      "\n",
      "[ Test epoch: 151]\n",
      "\n",
      "Test acuracy: 95.19\n",
      "Test average loss: 0.0020286518204957246\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 152]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002103716367855668\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.010866878554224968\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008142286678776145\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002424712060019374\n",
      "\n",
      "Total benign train accuracy: 99.982\n",
      "Total benign train loss: 0.7717894951347262\n",
      "\n",
      "[ Test epoch: 152]\n",
      "\n",
      "Test acuracy: 95.25\n",
      "Test average loss: 0.0020259803742170334\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 153]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0034828591160476208\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000702378514688462\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006070787203498185\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009683722746558487\n",
      "\n",
      "Total benign train accuracy: 99.984\n",
      "Total benign train loss: 0.7695895516080782\n",
      "\n",
      "[ Test epoch: 153]\n",
      "\n",
      "Test acuracy: 95.11\n",
      "Test average loss: 0.0020266585722565652\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 154]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012482749298214912\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.009188246913254261\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002468423219397664\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010833715787157416\n",
      "\n",
      "Total benign train accuracy: 99.984\n",
      "Total benign train loss: 0.743408759823069\n",
      "\n",
      "[ Test epoch: 154]\n",
      "\n",
      "Test acuracy: 95.22\n",
      "Test average loss: 0.002015187104791403\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 155]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017986359307542443\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009079569717869163\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002307323506101966\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014419179642573\n",
      "\n",
      "Total benign train accuracy: 99.968\n",
      "Total benign train loss: 0.7988428617245518\n",
      "\n",
      "[ Test epoch: 155]\n",
      "\n",
      "Test acuracy: 95.30999999999999\n",
      "Test average loss: 0.0020177571937441824\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 156]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008179976139217615\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0036174168344587088\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006383354775607586\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011750578414648771\n",
      "\n",
      "Total benign train accuracy: 99.978\n",
      "Total benign train loss: 0.7248619930760469\n",
      "\n",
      "[ Test epoch: 156]\n",
      "\n",
      "Test acuracy: 95.24000000000001\n",
      "Test average loss: 0.0020038243625313044\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 157]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014520706608891487\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005218781880103052\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008892211480997503\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0024301009252667427\n",
      "\n",
      "Total benign train accuracy: 99.984\n",
      "Total benign train loss: 0.6430098770360928\n",
      "\n",
      "[ Test epoch: 157]\n",
      "\n",
      "Test acuracy: 95.30999999999999\n",
      "Test average loss: 0.0020254574198275803\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 158]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016115143662318587\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003440841392148286\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001282641664147377\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018926712218672037\n",
      "\n",
      "Total benign train accuracy: 99.978\n",
      "Total benign train loss: 0.6690566102042794\n",
      "\n",
      "[ Test epoch: 158]\n",
      "\n",
      "Test acuracy: 95.19999999999999\n",
      "Test average loss: 0.0020361808132380245\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 159]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013508592965081334\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009231507428921759\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013766398187726736\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003962183545809239\n",
      "\n",
      "Total benign train accuracy: 99.988\n",
      "Total benign train loss: 0.6459591171733337\n",
      "\n",
      "[ Test epoch: 159]\n",
      "\n",
      "Test acuracy: 95.22\n",
      "Test average loss: 0.001997269231081009\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 160]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007732582162134349\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003606226062402129\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011371896835044026\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001210868707858026\n",
      "\n",
      "Total benign train accuracy: 99.996\n",
      "Total benign train loss: 0.5795725377392955\n",
      "\n",
      "[ Test epoch: 160]\n",
      "\n",
      "Test acuracy: 95.30999999999999\n",
      "Test average loss: 0.0020099682975560427\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 161]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000495767337270081\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008626764174550772\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015061041340231895\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009508717339485884\n",
      "\n",
      "Total benign train accuracy: 99.988\n",
      "Total benign train loss: 0.6251013521105051\n",
      "\n",
      "[ Test epoch: 161]\n",
      "\n",
      "Test acuracy: 95.16\n",
      "Test average loss: 0.0020151369359344244\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 162]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0028923028148710728\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017940147081390023\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009575828444212675\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0003882469900418073\n",
      "\n",
      "Total benign train accuracy: 99.982\n",
      "Total benign train loss: 0.679919108224567\n",
      "\n",
      "[ Test epoch: 162]\n",
      "\n",
      "Test acuracy: 95.23\n",
      "Test average loss: 0.0019966104798018933\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 163]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004010791890323162\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007018426549620926\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016623464180156589\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.006149424239993095\n",
      "\n",
      "Total benign train accuracy: 99.986\n",
      "Total benign train loss: 0.6131294539954979\n",
      "\n",
      "[ Test epoch: 163]\n",
      "\n",
      "Test acuracy: 95.22\n",
      "Test average loss: 0.001991177923604846\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 164]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006675339536741376\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015341643011197448\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008336481987498701\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018249501008540392\n",
      "\n",
      "Total benign train accuracy: 99.994\n",
      "Total benign train loss: 0.5632883676735219\n",
      "\n",
      "[ Test epoch: 164]\n",
      "\n",
      "Test acuracy: 95.17999999999999\n",
      "Test average loss: 0.00201269452534616\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 165]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009346940787509084\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011839533690363169\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016991245793178678\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009540267055854201\n",
      "\n",
      "Total benign train accuracy: 99.99\n",
      "Total benign train loss: 0.5669470387510955\n",
      "\n",
      "[ Test epoch: 165]\n",
      "\n",
      "Test acuracy: 95.23\n",
      "Test average loss: 0.0020148289799690245\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 166]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011511645279824734\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 0.9921875\n",
      "Current benign train loss: 0.012072905898094177\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001173664117231965\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008754616137593985\n",
      "\n",
      "Total benign train accuracy: 99.986\n",
      "Total benign train loss: 0.5970062648993917\n",
      "\n",
      "[ Test epoch: 166]\n",
      "\n",
      "Test acuracy: 95.13000000000001\n",
      "Test average loss: 0.0020136542454361915\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 167]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011459860252216458\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005282248021103442\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012142352061346173\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021806377917528152\n",
      "\n",
      "Total benign train accuracy: 99.992\n",
      "Total benign train loss: 0.5742418922309298\n",
      "\n",
      "[ Test epoch: 167]\n",
      "\n",
      "Test acuracy: 95.13000000000001\n",
      "Test average loss: 0.002016209592670202\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 168]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014355472521856427\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.003523648250848055\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008638612343929708\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008226337376981974\n",
      "\n",
      "Total benign train accuracy: 99.98\n",
      "Total benign train loss: 0.6155913827533368\n",
      "\n",
      "[ Test epoch: 168]\n",
      "\n",
      "Test acuracy: 95.21\n",
      "Test average loss: 0.0020023230735212567\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 169]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005782645312137902\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007385106291621923\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000559849024284631\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005653651314787567\n",
      "\n",
      "Total benign train accuracy: 99.986\n",
      "Total benign train loss: 0.5588207743421663\n",
      "\n",
      "[ Test epoch: 169]\n",
      "\n",
      "Test acuracy: 95.25\n",
      "Test average loss: 0.0019906785517930983\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 170]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007264462765306234\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019090792629867792\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00057318399194628\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008508260361850262\n",
      "\n",
      "Total benign train accuracy: 99.986\n",
      "Total benign train loss: 0.5824475829140283\n",
      "\n",
      "[ Test epoch: 170]\n",
      "\n",
      "Test acuracy: 95.26\n",
      "Test average loss: 0.0019890447247773407\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 171]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006114005227573216\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016392699908465147\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00037964145303703845\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00038482353556901217\n",
      "\n",
      "Total benign train accuracy: 99.982\n",
      "Total benign train loss: 0.6120208276552148\n",
      "\n",
      "[ Test epoch: 171]\n",
      "\n",
      "Test acuracy: 95.25\n",
      "Test average loss: 0.002008901236578822\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 172]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008989500347524881\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010821782052516937\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0021702188532799482\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015742357354611158\n",
      "\n",
      "Total benign train accuracy: 99.992\n",
      "Total benign train loss: 0.623149126622593\n",
      "\n",
      "[ Test epoch: 172]\n",
      "\n",
      "Test acuracy: 95.23\n",
      "Test average loss: 0.002003420469164848\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 173]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006288160802796483\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007476682658307254\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004910290008410811\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008951388881541789\n",
      "\n",
      "Total benign train accuracy: 99.988\n",
      "Total benign train loss: 0.5878769727569306\n",
      "\n",
      "[ Test epoch: 173]\n",
      "\n",
      "Test acuracy: 95.21\n",
      "Test average loss: 0.002009305180981755\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 174]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008275521686300635\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016014531720429659\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007669207989238203\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005327495746314526\n",
      "\n",
      "Total benign train accuracy: 99.986\n",
      "Total benign train loss: 0.5969663647993002\n",
      "\n",
      "[ Test epoch: 174]\n",
      "\n",
      "Test acuracy: 95.21\n",
      "Test average loss: 0.001989275012165308\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 175]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012872314546257257\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014156217221170664\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014242696342989802\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005349567509256303\n",
      "\n",
      "Total benign train accuracy: 99.994\n",
      "Total benign train loss: 0.5493451417132746\n",
      "\n",
      "[ Test epoch: 175]\n",
      "\n",
      "Test acuracy: 95.25\n",
      "Test average loss: 0.0020023723434656857\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 176]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018923392053693533\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00093607057351619\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002552475081756711\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008431094465777278\n",
      "\n",
      "Total benign train accuracy: 99.99\n",
      "Total benign train loss: 0.5358910885552177\n",
      "\n",
      "[ Test epoch: 176]\n",
      "\n",
      "Test acuracy: 95.28999999999999\n",
      "Test average loss: 0.0019863176357001067\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 177]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008666178910061717\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006528606754727662\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.004468847531825304\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018221555510535836\n",
      "\n",
      "Total benign train accuracy: 99.986\n",
      "Total benign train loss: 0.5888952017994598\n",
      "\n",
      "[ Test epoch: 177]\n",
      "\n",
      "Test acuracy: 95.14\n",
      "Test average loss: 0.0020057640671730043\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 178]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014094142243266106\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020808458793908358\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011238852748647332\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00038726170896552503\n",
      "\n",
      "Total benign train accuracy: 99.99\n",
      "Total benign train loss: 0.5808827375876717\n",
      "\n",
      "[ Test epoch: 178]\n",
      "\n",
      "Test acuracy: 95.13000000000001\n",
      "Test average loss: 0.002003379273042083\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 179]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000577942468225956\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0023115735966712236\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005763263907283545\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0036182738840579987\n",
      "\n",
      "Total benign train accuracy: 99.988\n",
      "Total benign train loss: 0.6151961874857079\n",
      "\n",
      "[ Test epoch: 179]\n",
      "\n",
      "Test acuracy: 95.17\n",
      "Test average loss: 0.001995333803445101\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 180]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005138159031048417\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012058509746566415\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010118944337591529\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.002758315298706293\n",
      "\n",
      "Total benign train accuracy: 99.984\n",
      "Total benign train loss: 0.5972151534515433\n",
      "\n",
      "[ Test epoch: 180]\n",
      "\n",
      "Test acuracy: 95.21\n",
      "Test average loss: 0.0019948456291109325\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 181]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00041811238043010235\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0019073868170380592\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006825039745308459\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0025977841578423977\n",
      "\n",
      "Total benign train accuracy: 99.998\n",
      "Total benign train loss: 0.49336385511560366\n",
      "\n",
      "[ Test epoch: 181]\n",
      "\n",
      "Test acuracy: 95.13000000000001\n",
      "Test average loss: 0.0019978093199431897\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 182]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001144235604442656\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005494622164405882\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012773133348673582\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0014606663025915623\n",
      "\n",
      "Total benign train accuracy: 99.992\n",
      "Total benign train loss: 0.5442377818399109\n",
      "\n",
      "[ Test epoch: 182]\n",
      "\n",
      "Test acuracy: 95.14\n",
      "Test average loss: 0.0019960066262632607\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 183]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009078443399630487\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007980468799360096\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0046419622376561165\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006223336677066982\n",
      "\n",
      "Total benign train accuracy: 99.992\n",
      "Total benign train loss: 0.5273835496045649\n",
      "\n",
      "[ Test epoch: 183]\n",
      "\n",
      "Test acuracy: 95.14\n",
      "Test average loss: 0.001981049132347107\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 184]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015419117407873273\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007849075482226908\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0037215843331068754\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001022464595735073\n",
      "\n",
      "Total benign train accuracy: 99.994\n",
      "Total benign train loss: 0.516552235436393\n",
      "\n",
      "[ Test epoch: 184]\n",
      "\n",
      "Test acuracy: 95.21\n",
      "Test average loss: 0.001994163433462381\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 185]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009848634945228696\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015499675646424294\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001084300223737955\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001262392965145409\n",
      "\n",
      "Total benign train accuracy: 99.994\n",
      "Total benign train loss: 0.5403276793513214\n",
      "\n",
      "[ Test epoch: 185]\n",
      "\n",
      "Test acuracy: 95.17\n",
      "Test average loss: 0.002005809349194169\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 186]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017971399938687682\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006656423793174326\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010732811642810702\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009323076228611171\n",
      "\n",
      "Total benign train accuracy: 99.998\n",
      "Total benign train loss: 0.5002101933641825\n",
      "\n",
      "[ Test epoch: 186]\n",
      "\n",
      "Test acuracy: 95.14\n",
      "Test average loss: 0.0019929842595010996\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 187]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00038405199302360415\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018514178227633238\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001955195562914014\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0016847120132297277\n",
      "\n",
      "Total benign train accuracy: 99.992\n",
      "Total benign train loss: 0.5011433108011261\n",
      "\n",
      "[ Test epoch: 187]\n",
      "\n",
      "Test acuracy: 95.07\n",
      "Test average loss: 0.0020062473312020303\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 188]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008652193937450647\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005808781133964658\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020392821170389652\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007166097639128566\n",
      "\n",
      "Total benign train accuracy: 99.988\n",
      "Total benign train loss: 0.585858494247077\n",
      "\n",
      "[ Test epoch: 188]\n",
      "\n",
      "Test acuracy: 95.21\n",
      "Test average loss: 0.0019951562829315663\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 189]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0008248362573795021\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0048275114968419075\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006394936935976148\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000852682685945183\n",
      "\n",
      "Total benign train accuracy: 99.988\n",
      "Total benign train loss: 0.5714314139331691\n",
      "\n",
      "[ Test epoch: 189]\n",
      "\n",
      "Test acuracy: 95.16\n",
      "Test average loss: 0.001985030245408416\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 190]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004858694155700505\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006575730512849987\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.000998504925519228\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001917558372952044\n",
      "\n",
      "Total benign train accuracy: 99.988\n",
      "Total benign train loss: 0.5623209935438354\n",
      "\n",
      "[ Test epoch: 190]\n",
      "\n",
      "Test acuracy: 95.16\n",
      "Test average loss: 0.001988604895025492\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 191]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006602289504371583\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005346655962057412\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007332105305977166\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011692672269418836\n",
      "\n",
      "Total benign train accuracy: 99.992\n",
      "Total benign train loss: 0.5140834385238122\n",
      "\n",
      "[ Test epoch: 191]\n",
      "\n",
      "Test acuracy: 95.17999999999999\n",
      "Test average loss: 0.0019882326666265725\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 192]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001027154503390193\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011904120910912752\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017665403429418802\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0006726527935825288\n",
      "\n",
      "Total benign train accuracy: 99.994\n",
      "Total benign train loss: 0.5157491954159923\n",
      "\n",
      "[ Test epoch: 192]\n",
      "\n",
      "Test acuracy: 95.17999999999999\n",
      "Test average loss: 0.001993276907503605\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 193]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0024821311235427856\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010748491622507572\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010896635940298438\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009030548972077668\n",
      "\n",
      "Total benign train accuracy: 99.986\n",
      "Total benign train loss: 0.5921558397240005\n",
      "\n",
      "[ Test epoch: 193]\n",
      "\n",
      "Test acuracy: 95.15\n",
      "Test average loss: 0.0019613042421638967\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 194]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0004794954729732126\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0028184971306473017\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011765665840357542\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0020583372097462416\n",
      "\n",
      "Total benign train accuracy: 99.996\n",
      "Total benign train loss: 0.4970151391753461\n",
      "\n",
      "[ Test epoch: 194]\n",
      "\n",
      "Test acuracy: 95.16\n",
      "Test average loss: 0.0019859599586576223\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 195]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009500166052021086\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013060923665761948\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0013870924012735486\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0034785359166562557\n",
      "\n",
      "Total benign train accuracy: 99.996\n",
      "Total benign train loss: 0.49129545033792965\n",
      "\n",
      "[ Test epoch: 195]\n",
      "\n",
      "Test acuracy: 95.17\n",
      "Test average loss: 0.001970514111220837\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 196]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001647057943046093\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0010915582533925772\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0012687213020399213\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.00028764831949956715\n",
      "\n",
      "Total benign train accuracy: 99.99\n",
      "Total benign train loss: 0.5687055125890765\n",
      "\n",
      "[ Test epoch: 196]\n",
      "\n",
      "Test acuracy: 95.21\n",
      "Test average loss: 0.001977392378076911\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 197]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011173932580277324\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007673354120925069\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001238928991369903\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0018086364725604653\n",
      "\n",
      "Total benign train accuracy: 99.992\n",
      "Total benign train loss: 0.4978321840753779\n",
      "\n",
      "[ Test epoch: 197]\n",
      "\n",
      "Test acuracy: 95.21\n",
      "Test average loss: 0.0019620552070438863\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 198]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0005967089091427624\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0007673645741306245\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0017759985057637095\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0002999006537720561\n",
      "\n",
      "Total benign train accuracy: 99.99\n",
      "Total benign train loss: 0.5788466870435514\n",
      "\n",
      "[ Test epoch: 198]\n",
      "\n",
      "Test acuracy: 95.21\n",
      "Test average loss: 0.001972948217764497\n",
      "Model Saved!\n",
      "\n",
      "[ Train epoch: 199]\n",
      "\n",
      "Current batch: 0\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0011804519454017282\n",
      "\n",
      "Current batch: 100\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0009172754944302142\n",
      "\n",
      "Current batch: 200\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.001020294614136219\n",
      "\n",
      "Current batch: 300\n",
      "Current benign train accuracy: 1.0\n",
      "Current benign train loss: 0.0015683399979025126\n",
      "\n",
      "Total benign train accuracy: 99.988\n",
      "Total benign train loss: 0.49583154934225604\n",
      "\n",
      "[ Test epoch: 199]\n",
      "\n",
      "Test acuracy: 95.28\n",
      "Test average loss: 0.001976975245028734\n",
      "Model Saved!\n"
     ]
    }
   ],
   "source": [
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(0, 200):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "    train_accuracies.append(train(epoch))\n",
    "    test_accuracies.append(test(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.plot(range(1, 201), train_accuracies, label='Train Accuracy')\n",
    "plt.plot(range(1, 201), test_accuracies, label='Test Accuracy')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cifar10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
